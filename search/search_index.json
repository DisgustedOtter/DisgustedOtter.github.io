{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Objetivo La implementaci\u00f3n del Elastic Stack corresponde a la necesidad de centralizar los logs que generan los sistemas MCS, COMPS, DDS, INACS, MAS y MACOPS. Previo a esto la consulta de los mismos s\u00f3lo se pod\u00eda realizar entrando directamente a cada servidor, lo que supone una tarea poco pr\u00e1ctica. Ahora se pueden consultar en un mismo sitio y realizar filtraciones y reportes. Arquitectura General El Stack se conforma de la siguiente manera: Cada servidor de aplicaciones o servicios tendr\u00e1 como agente recolector Filebeat o Winlogbeat (ambos son parte de una plataforma llamada Beats ), el primero para los sistemas que generen logs mediante ficheros y el segundo para aquellos que los generen como logs de Windows. Estos enviar\u00e1n la informaci\u00f3n a Logstash . 5 servidores con Logstash que se encargar\u00e1n de recibir, filtrar, transformar y dar formato a los logs que ser\u00e1n enviados a Elasticsearch . 4 nodos de Elasticsearch comunicados entre s\u00ed que forman un cluster llamado jygacluster. En ellos se guarda la informaci\u00f3n de los logs. 1 instancia de Kibana que es el cliente con el que un usuario puede visualizar la informacion alojada en Elasticsearch.","title":"Objetivo"},{"location":"index.html#objetivo","text":"La implementaci\u00f3n del Elastic Stack corresponde a la necesidad de centralizar los logs que generan los sistemas MCS, COMPS, DDS, INACS, MAS y MACOPS. Previo a esto la consulta de los mismos s\u00f3lo se pod\u00eda realizar entrando directamente a cada servidor, lo que supone una tarea poco pr\u00e1ctica. Ahora se pueden consultar en un mismo sitio y realizar filtraciones y reportes.","title":"Objetivo"},{"location":"index.html#arquitectura-general","text":"El Stack se conforma de la siguiente manera: Cada servidor de aplicaciones o servicios tendr\u00e1 como agente recolector Filebeat o Winlogbeat (ambos son parte de una plataforma llamada Beats ), el primero para los sistemas que generen logs mediante ficheros y el segundo para aquellos que los generen como logs de Windows. Estos enviar\u00e1n la informaci\u00f3n a Logstash . 5 servidores con Logstash que se encargar\u00e1n de recibir, filtrar, transformar y dar formato a los logs que ser\u00e1n enviados a Elasticsearch . 4 nodos de Elasticsearch comunicados entre s\u00ed que forman un cluster llamado jygacluster. En ellos se guarda la informaci\u00f3n de los logs. 1 instancia de Kibana que es el cliente con el que un usuario puede visualizar la informacion alojada en Elasticsearch.","title":"Arquitectura General"},{"location":"2%20Previo%20a%20la%20instalacion.html","text":"Previo a la instalaci\u00f3n del stack Variable de entorno Java Antes de comenzar con la instalaci\u00f3n de Elastic Search se debe revisar si el servidor tiene configurada la variable de entorno ES_JAVA_HOME : Es importante que est\u00e9 incluido en el apartado de variables del sistema y no en variables de usuario. De no ser as\u00ed, seguir las instrucciones a continuaci\u00f3n. Instalaci\u00f3n de Java Descargar Java Runtime Environment (JRE) del sitio oficial Instalar Java siguiendo las configuraciones por default que ofrece el wizard, en caso de ser necesario s\u00f3lo se podr\u00e1 cambiar la ubicaci\u00f3n de la carpeta de instalaci\u00f3n. Ubicar y copiar la ruta de la carpeta donde se instal\u00f3, por default es Program Files(x86)/Java/jre[VERSION] . A\u00f1adir variable de entorno Dar click en el bot\u00f3n Nueva\u2026 del apartado Variables del sistema En la ventana que se despliega, llenar los dos campos que se piden; El Nombre de la variable deber ser estrictamente ES_JAVA_HOME , y en Valor de la variable pegar la direcci\u00f3n que se copi\u00f3 anteriormente cuando se instal\u00f3 Java. dar click en Aceptar Verificar que la variable se haya a\u00f1adido correctamente","title":"Previo a la instalaci\u00f3n del stack"},{"location":"2%20Previo%20a%20la%20instalacion.html#previo-a-la-instalacion-del-stack","text":"","title":"Previo a la instalaci\u00f3n del stack"},{"location":"2%20Previo%20a%20la%20instalacion.html#variable-de-entorno-java","text":"Antes de comenzar con la instalaci\u00f3n de Elastic Search se debe revisar si el servidor tiene configurada la variable de entorno ES_JAVA_HOME : Es importante que est\u00e9 incluido en el apartado de variables del sistema y no en variables de usuario. De no ser as\u00ed, seguir las instrucciones a continuaci\u00f3n.","title":"Variable de entorno Java"},{"location":"2%20Previo%20a%20la%20instalacion.html#instalacion-de-java","text":"Descargar Java Runtime Environment (JRE) del sitio oficial Instalar Java siguiendo las configuraciones por default que ofrece el wizard, en caso de ser necesario s\u00f3lo se podr\u00e1 cambiar la ubicaci\u00f3n de la carpeta de instalaci\u00f3n. Ubicar y copiar la ruta de la carpeta donde se instal\u00f3, por default es Program Files(x86)/Java/jre[VERSION] .","title":"Instalaci\u00f3n de Java"},{"location":"2%20Previo%20a%20la%20instalacion.html#anadir-variable-de-entorno","text":"Dar click en el bot\u00f3n Nueva\u2026 del apartado Variables del sistema En la ventana que se despliega, llenar los dos campos que se piden; El Nombre de la variable deber ser estrictamente ES_JAVA_HOME , y en Valor de la variable pegar la direcci\u00f3n que se copi\u00f3 anteriormente cuando se instal\u00f3 Java. dar click en Aceptar Verificar que la variable se haya a\u00f1adido correctamente","title":"A\u00f1adir variable de entorno"},{"location":"Beats/1I%20ndex.html","text":"Introducci\u00f3n Beats es una plataforma de agentes que tienen como prop\u00f3sito recolectar y enviar datos (en este caso los Logs de cada sistema) ya sea directamente a Elasticsearch o a Logstash como intermediario para que los procece. Existen varios agentes , pero s\u00f3lo fue necesario usar Filebeat y Winlogbeat.","title":"Introducci\u00f3n"},{"location":"Beats/1I%20ndex.html#introduccion","text":"Beats es una plataforma de agentes que tienen como prop\u00f3sito recolectar y enviar datos (en este caso los Logs de cada sistema) ya sea directamente a Elasticsearch o a Logstash como intermediario para que los procece. Existen varios agentes , pero s\u00f3lo fue necesario usar Filebeat y Winlogbeat.","title":"Introducci\u00f3n"},{"location":"Beats/Filebeat.html","text":"Filebeat Se instala en los sistemas que generan datos en ficheros como el siguiente: Instalaci\u00f3n Descargar el paquete del sitio oficial Descomprimir el fichero en la ubicaci\u00f3n deseada. Abrir powershell con permisos de administraci\u00f3n y ubicarse en la carpeta de instalcion de Filebeat y ejecutar el siguiente comando para instalarlo como servicio de Windows .\\install-service-filebeat Configuraci\u00f3n El archivo de configuraci\u00f3n es Filebeat.yml y se encuentra en la ruta C:\\Program Files\\filebeat En la secci\u00f3n llamada filebeat.inputs: se indica la direcci\u00f3n de los ficheros logs a enviar, lo elementos hijos tienen la siguiente estructura: - type: log enabled: true paths: - C:\\DDS Win Services\\COMPASDDS.MaintenaceService\\Logs\\COMPASDDS.MaintenanceService .log ignore_older: 170h fields: service name: CompasDDS.MaintenanceService system: dds multiline.pattern: ^{ multiline.negate: true multiline.match: after exclude_lines: ['{INFO}. '] donde: type: log Es el tipo de archivo a procesar, en este casoo son de extension tipo .log enabled: true se habilita este input paths: se especifica la ruta del archivo log fields: en este apartado se agregan campos personalizados, los que se agregaron fue para poder filtrar los logs por sistema y por nombre de servicio. multiline.pattern Cuando se cumpla ese patr\u00f3n Filebeat sabr\u00e1 que inicia un nuevo registro de log multiline.negate niega como una nueva linea lo que no cumpla el patr\u00f3n anterior multiline.match indica hcia qu\u00e9 parte de la cadena debe analizar exclude_lines excluye lineas que empiezen por cierto patr\u00f3n. Algunos sistemas como el DDS generan una cantidad excesiva de logs, y se decidi\u00f3 incluir s\u00f3lo los de tipo ERROR . Se puede optar por incluir metada de Filebeat que da informaci\u00f3n acerca del servidor donde est\u00e1 alojado, se incluy\u00f3 para incluir el nombre del host. Para habilitarlo: processors: - add_host_metadata: netinfo.enabled: true Por \u00faltimo se establece la direcci\u00f3n IP del servidor con Logstash que har\u00e1 el tratamiento de los datos: output.logstash: # The Logstash hosts hosts: [\"10.91.116.37:5044\"] En la imagen de la Arquitectura General se indica la conex\u00f3n existente entre cada servidor. Una vez agregados todo los inputs se inicia el servicio.","title":"Filebeat"},{"location":"Beats/Filebeat.html#filebeat","text":"Se instala en los sistemas que generan datos en ficheros como el siguiente:","title":"Filebeat"},{"location":"Beats/Filebeat.html#instalacion","text":"Descargar el paquete del sitio oficial Descomprimir el fichero en la ubicaci\u00f3n deseada. Abrir powershell con permisos de administraci\u00f3n y ubicarse en la carpeta de instalcion de Filebeat y ejecutar el siguiente comando para instalarlo como servicio de Windows .\\install-service-filebeat","title":"Instalaci\u00f3n"},{"location":"Beats/Filebeat.html#configuracion","text":"El archivo de configuraci\u00f3n es Filebeat.yml y se encuentra en la ruta C:\\Program Files\\filebeat En la secci\u00f3n llamada filebeat.inputs: se indica la direcci\u00f3n de los ficheros logs a enviar, lo elementos hijos tienen la siguiente estructura: - type: log enabled: true paths: - C:\\DDS Win Services\\COMPASDDS.MaintenaceService\\Logs\\COMPASDDS.MaintenanceService .log ignore_older: 170h fields: service name: CompasDDS.MaintenanceService system: dds multiline.pattern: ^{ multiline.negate: true multiline.match: after exclude_lines: ['{INFO}. '] donde: type: log Es el tipo de archivo a procesar, en este casoo son de extension tipo .log enabled: true se habilita este input paths: se especifica la ruta del archivo log fields: en este apartado se agregan campos personalizados, los que se agregaron fue para poder filtrar los logs por sistema y por nombre de servicio. multiline.pattern Cuando se cumpla ese patr\u00f3n Filebeat sabr\u00e1 que inicia un nuevo registro de log multiline.negate niega como una nueva linea lo que no cumpla el patr\u00f3n anterior multiline.match indica hcia qu\u00e9 parte de la cadena debe analizar exclude_lines excluye lineas que empiezen por cierto patr\u00f3n. Algunos sistemas como el DDS generan una cantidad excesiva de logs, y se decidi\u00f3 incluir s\u00f3lo los de tipo ERROR . Se puede optar por incluir metada de Filebeat que da informaci\u00f3n acerca del servidor donde est\u00e1 alojado, se incluy\u00f3 para incluir el nombre del host. Para habilitarlo: processors: - add_host_metadata: netinfo.enabled: true Por \u00faltimo se establece la direcci\u00f3n IP del servidor con Logstash que har\u00e1 el tratamiento de los datos: output.logstash: # The Logstash hosts hosts: [\"10.91.116.37:5044\"] En la imagen de la Arquitectura General se indica la conex\u00f3n existente entre cada servidor. Una vez agregados todo los inputs se inicia el servicio.","title":"Configuraci\u00f3n"},{"location":"Beats/Winlogbeat.html","text":"Winlogbeat Se instala en los sistemas que genera los logs como eventos de Windows como el siguiente: Instalaci\u00f3n Descargar el paquete del sitio oficial Descomprimir el fichero en la ubicaci\u00f3n deseada. Abrir powershell con permisos de administraci\u00f3n y ubicarse en la carpeta de instalcion de Filebeat y ejecutar el siguiente comando para instalarlo como servicio de Windows .\\install-service-winlogbeat Configuraci\u00f3n El archivo de configuraci\u00f3n es Winlogbeat.yml y se encuentra en la ruta C:\\Program Files\\winlogbeat . La secci\u00f3n donde establecen los inputs en winlogbeat es en winlogbeat.event_logs , los elementos hijos tienen la siguiente estructura: - name: Atlas ignore_older: 48h fields: service name: MAS.Atlas.Service system: mas donde: name es el nombre del servicio como aparece en el Event Viewer ignore_older winlogbeat ignorar\u00e1 a los logs con fechas mayores al numero que se poga, tiene sufijo h y se refiere a horas. Este par\u00e1metro s\u00f3lo se toma en cuenta cuando se inicia el servicio. fields como en Filebeat tambi\u00e9n se pueden agregar campos personalizados. Los datos son enviados a Logstash: output.logstash: # The Logstash hosts hosts: [\"10.91.116.74:5044\"] Iniciar el servicio al terminar de agregar todo los inputs.","title":"Winlogbeat"},{"location":"Beats/Winlogbeat.html#winlogbeat","text":"Se instala en los sistemas que genera los logs como eventos de Windows como el siguiente:","title":"Winlogbeat"},{"location":"Beats/Winlogbeat.html#instalacion","text":"Descargar el paquete del sitio oficial Descomprimir el fichero en la ubicaci\u00f3n deseada. Abrir powershell con permisos de administraci\u00f3n y ubicarse en la carpeta de instalcion de Filebeat y ejecutar el siguiente comando para instalarlo como servicio de Windows .\\install-service-winlogbeat","title":"Instalaci\u00f3n"},{"location":"Beats/Winlogbeat.html#configuracion","text":"El archivo de configuraci\u00f3n es Winlogbeat.yml y se encuentra en la ruta C:\\Program Files\\winlogbeat . La secci\u00f3n donde establecen los inputs en winlogbeat es en winlogbeat.event_logs , los elementos hijos tienen la siguiente estructura: - name: Atlas ignore_older: 48h fields: service name: MAS.Atlas.Service system: mas donde: name es el nombre del servicio como aparece en el Event Viewer ignore_older winlogbeat ignorar\u00e1 a los logs con fechas mayores al numero que se poga, tiene sufijo h y se refiere a horas. Este par\u00e1metro s\u00f3lo se toma en cuenta cuando se inicia el servicio. fields como en Filebeat tambi\u00e9n se pueden agregar campos personalizados. Los datos son enviados a Logstash: output.logstash: # The Logstash hosts hosts: [\"10.91.116.74:5044\"] Iniciar el servicio al terminar de agregar todo los inputs.","title":"Configuraci\u00f3n"},{"location":"Elasticsearch/1%20Instalaci%C3%B3n.html","text":"Instalaci\u00f3n Elasticsearch puede ser instalado en entornos Linux y Windows, al momento de la realizaci\u00f3n de este documento se instal\u00f3 la \u00faltima versi\u00f3n (7.16) de Windows Descargar el paquete del sitio oficial . Descomprimir el archivo zip en cualquier ubicaci\u00f3n deseada. Abrir cmd con permisos de administrador, ubicarse en la carpeta bin y ejecutar el bat elasticsearch-service.bat con el par\u00e1metro install para instalar Elasticsearch como un servicio de Windows Al final aparecer\u00e1 que el servicio se ha instalado correctamente. Aunque en este momento es posible iniciar directamente el servicio, es conveniente asignar la memoria que utilizar\u00e1 elastic search, esto se explica a continuaci\u00f3n.","title":"Instalaci\u00f3n"},{"location":"Elasticsearch/1%20Instalaci%C3%B3n.html#instalacion","text":"Elasticsearch puede ser instalado en entornos Linux y Windows, al momento de la realizaci\u00f3n de este documento se instal\u00f3 la \u00faltima versi\u00f3n (7.16) de Windows Descargar el paquete del sitio oficial . Descomprimir el archivo zip en cualquier ubicaci\u00f3n deseada. Abrir cmd con permisos de administrador, ubicarse en la carpeta bin y ejecutar el bat elasticsearch-service.bat con el par\u00e1metro install para instalar Elasticsearch como un servicio de Windows Al final aparecer\u00e1 que el servicio se ha instalado correctamente. Aunque en este momento es posible iniciar directamente el servicio, es conveniente asignar la memoria que utilizar\u00e1 elastic search, esto se explica a continuaci\u00f3n.","title":"Instalaci\u00f3n"},{"location":"Elasticsearch/2%20Configuraci%C3%B3n.html","text":"Configuraci\u00f3n Existen principalmente 2 archivos que se encargan de la configuraci\u00f3n de ElasticSearch: jvm.options y elasticsearch.yml , se explicar\u00e1 cada una de las l\u00edneas que fueron modificadas de los par\u00e1metros est\u00e1ndar. Jvm.options Cuando se ejecuta Elastic Search se crea una maquina virtual de proceso nativo llamada Java Virtual Machine (JVM). La memoria que se asigna a esta m\u00e1quina virtual se realiza autom\u00e1ticamente en base a los recursos del servidor y los roles del nodo. Sin embargo, al tener otros procesos en el servidor es conveniente ajustar esta memoria para no afectarlos y tener mayor control sobre el servicio de Elastic Search. Este archivo se encuentra en la direcci\u00f3n C:\\Program Files\\elasticsearch-7.16.1\\config\\ La secci\u00f3n de inter\u00e9s se llama JVM heap size . Si bien es posible hacer las modificaciones sobre este archivo, como buena pr\u00e1ctica y recomendaci\u00f3n misma de Elastic, se crea otro archivo con mismo nombre y extensi\u00f3n para ubicarlo en el directorio C:\\Program Files\\elasticsearch-7.16.1\\config\\jvm.options.d En ese archivo escribir lo siguiente: -Xms2g -Xmx2g Donde el valor num\u00e9rico no debe ser mayor al 50% de la memoria total del servidor y se recomienda que los dos valores sean iguales; en este caso se est\u00e1 asignando 2GB de memoria m\u00ednima y m\u00e1xima para la m\u00e1quina virtual. Tambi\u00e9n por cuestiones de Java no es recomendable pasar de 32 GB. Una vez modificado esto, iniciar el servicio de elastic search La comunicaci\u00f3n se realiza por medio del puerto 9200, si se visita la direcci\u00f3n http://localhost:9200/ se muestra la informaci\u00f3n de la instancia: Siguiendo los pasos anteriores hasta este punto se puede realizar la instalaci\u00f3n de ElasticSearch en todos los servidores que se requiera. En la siguiente secci\u00f3n se cubren los aspectos necesarios para la comunicaci\u00f3n entre ellos y la implementaci\u00f3n de seguridad. ElasticSearch.yml Este archivo contiene la mayor parte de la configuraci\u00f3n de Elastic Search, se encuentra en la direcci\u00f3n C:\\Program Files\\elasticsearch-7.16.1\\config\\elasticsearch.yml y a diferencia del archivo jvm.options se edita directamente sobre el fichero sin tener que crear otro. Los datos usados a partir de ahora corresponden para el servidor 10.91.116.215 que forma parte del cluster presentado en la secci\u00f3n de Arquitectura General y f\u00e1cilmente se puede usar de ejemplo para la configuraci\u00f3n de otras instancias de Elasticsearch. Configuraci\u00f3n inicial Se le llama cluster al conjunto de servidores con instancias de Elastic Search comunicadas entre s\u00ed. Un cluster se puede formar a partir de 1 instancia. Por defecto se le asigna el nombre elasticsearch , el cual se deber\u00eda cambiar para evitar que accidentalmente una instancia se una a un cluster no deseado. Para ello solo hace falta descomentar la siguiente l\u00ednea y poner el nombre que se quiera: # ---------------------------------- Cluster ----------------------------------- # Use a descriptive name for your cluster: cluster.name: jygacluster Un cluster se conforma de nodos, es decir, cada servidor con Elastic Search representa un nodo. Tambi\u00e9n es recomendable modificar el nombre por defecto en caso de que se vayan a crear varios nodos, en este caso se eligi\u00f3 con el sufijo 215 haciendo referencia a la direcci\u00f3n IP del servidor donde se encuentra alojado: 10.91.116.215. Los dem\u00e1s nodos fueron nombrados con la misma regla. # ------------------------------------ Node ------------------------------------ # Use a descriptive name for the node: node.name: node-215 El siguiente par\u00e1metro asegura que la memoria asignada previamente en el archivo jvm.opt se bloque\u00e9 para otras aplicaciones y sea para uso exclusivo de Elasticsearch. Su performance disminuye si esto no se cambia y realiza swapping de memoria. # ----------------------------------- Memory ----------------------------------- # Lock the memory on startup: bootstrap.memory_lock: true Como la intenci\u00f3n es crear un cluster con varios nodos, se coloca la direcci\u00f3n IP para que otros servidores se puedan comunicar con el nodo. # ---------------------------------- Network ----------------------------------- # By default Elasticsearch is only accessible on localhost. Set a different # address here to expose this node on the network: network.host: 10.91.116.215 Como ya se prob\u00f3 anteriormente, por defecto Elasticsearch se comunica por medio del puerto 9200, si se requiere cambiar esto se modifica la siguiente l\u00ednea: # By default Elasticsearch listens for HTTP traffic on the first free port it # finds starting at 9200. Set a specific HTTP port here: http.port: 9200 Aqu\u00ed se establece que el nodo puede ser elegido maestro. Un nodo maestro tiene la faculta de administrar el cl\u00faster. node.master: true Se agrega la direcci\u00f3n IP de los dem\u00e1s servidores con los que deber\u00e1 tener comunicaci\u00f3n el nodo, como en este caso se est\u00e1 configurando el nodo-215 se excluye de la lista y queda de la siguiente forma: # --------------------------------- Discovery ---------------------------------- # Pass an initial list of hosts to perform discovery when this node is started: # The default list of hosts is [\"127.0.0.1\", \"[::1]\"] discovery.seed_hosts: [\"10.91.116.145\", \"10.91.116.56\", \"10.91.116.172\"] Entonces siguiendo la l\u00f3gica anterior, la configuraci\u00f3n del nodo-56 es as\u00ed: # --------------------------------- Discovery ---------------------------------- # Pass an initial list of hosts to perform discovery when this node is started: # The default list of hosts is [\"127.0.0.1\", \"[::1]\"] discovery.seed_hosts: [\"10.91.116.145\", \"10.91.116.215\", \"10.91.116.172\"] Y as\u00ed sucesivamente con los dem\u00e1s nodos. En el siguiente par\u00e1metro se incluye el nombre de los nodos maestros iniciales, si al arranque de Elasticsearch falla la comunicaci\u00f3n con alguno de ellos, el nodo incomunicado no podr\u00e1 unirse al cluster y el servicio se detendr\u00e1 para evitar que cre\u00e9 uno propio: # Bootstrap the cluster using an initial set of master-eligible nodes: cluster.initial_master_nodes: [\"node-145\", \"node-56\"] Los servidores usados no tienen acceso a internet, as\u00ed que se debe agregar la siguiente l\u00ednea para evitar el error al querer descargar la caracter\u00edstica de geolocalizaci\u00f3n de IP en el arranque del servicio: ingest.geoip.downloader.enabled: false","title":"Configuraci\u00f3n"},{"location":"Elasticsearch/2%20Configuraci%C3%B3n.html#configuracion","text":"Existen principalmente 2 archivos que se encargan de la configuraci\u00f3n de ElasticSearch: jvm.options y elasticsearch.yml , se explicar\u00e1 cada una de las l\u00edneas que fueron modificadas de los par\u00e1metros est\u00e1ndar.","title":"Configuraci\u00f3n"},{"location":"Elasticsearch/2%20Configuraci%C3%B3n.html#jvmoptions","text":"Cuando se ejecuta Elastic Search se crea una maquina virtual de proceso nativo llamada Java Virtual Machine (JVM). La memoria que se asigna a esta m\u00e1quina virtual se realiza autom\u00e1ticamente en base a los recursos del servidor y los roles del nodo. Sin embargo, al tener otros procesos en el servidor es conveniente ajustar esta memoria para no afectarlos y tener mayor control sobre el servicio de Elastic Search. Este archivo se encuentra en la direcci\u00f3n C:\\Program Files\\elasticsearch-7.16.1\\config\\ La secci\u00f3n de inter\u00e9s se llama JVM heap size . Si bien es posible hacer las modificaciones sobre este archivo, como buena pr\u00e1ctica y recomendaci\u00f3n misma de Elastic, se crea otro archivo con mismo nombre y extensi\u00f3n para ubicarlo en el directorio C:\\Program Files\\elasticsearch-7.16.1\\config\\jvm.options.d En ese archivo escribir lo siguiente: -Xms2g -Xmx2g Donde el valor num\u00e9rico no debe ser mayor al 50% de la memoria total del servidor y se recomienda que los dos valores sean iguales; en este caso se est\u00e1 asignando 2GB de memoria m\u00ednima y m\u00e1xima para la m\u00e1quina virtual. Tambi\u00e9n por cuestiones de Java no es recomendable pasar de 32 GB. Una vez modificado esto, iniciar el servicio de elastic search La comunicaci\u00f3n se realiza por medio del puerto 9200, si se visita la direcci\u00f3n http://localhost:9200/ se muestra la informaci\u00f3n de la instancia: Siguiendo los pasos anteriores hasta este punto se puede realizar la instalaci\u00f3n de ElasticSearch en todos los servidores que se requiera. En la siguiente secci\u00f3n se cubren los aspectos necesarios para la comunicaci\u00f3n entre ellos y la implementaci\u00f3n de seguridad.","title":"Jvm.options"},{"location":"Elasticsearch/2%20Configuraci%C3%B3n.html#elasticsearchyml","text":"Este archivo contiene la mayor parte de la configuraci\u00f3n de Elastic Search, se encuentra en la direcci\u00f3n C:\\Program Files\\elasticsearch-7.16.1\\config\\elasticsearch.yml y a diferencia del archivo jvm.options se edita directamente sobre el fichero sin tener que crear otro. Los datos usados a partir de ahora corresponden para el servidor 10.91.116.215 que forma parte del cluster presentado en la secci\u00f3n de Arquitectura General y f\u00e1cilmente se puede usar de ejemplo para la configuraci\u00f3n de otras instancias de Elasticsearch.","title":"ElasticSearch.yml"},{"location":"Elasticsearch/2%20Configuraci%C3%B3n.html#configuracion-inicial","text":"Se le llama cluster al conjunto de servidores con instancias de Elastic Search comunicadas entre s\u00ed. Un cluster se puede formar a partir de 1 instancia. Por defecto se le asigna el nombre elasticsearch , el cual se deber\u00eda cambiar para evitar que accidentalmente una instancia se una a un cluster no deseado. Para ello solo hace falta descomentar la siguiente l\u00ednea y poner el nombre que se quiera: # ---------------------------------- Cluster ----------------------------------- # Use a descriptive name for your cluster: cluster.name: jygacluster Un cluster se conforma de nodos, es decir, cada servidor con Elastic Search representa un nodo. Tambi\u00e9n es recomendable modificar el nombre por defecto en caso de que se vayan a crear varios nodos, en este caso se eligi\u00f3 con el sufijo 215 haciendo referencia a la direcci\u00f3n IP del servidor donde se encuentra alojado: 10.91.116.215. Los dem\u00e1s nodos fueron nombrados con la misma regla. # ------------------------------------ Node ------------------------------------ # Use a descriptive name for the node: node.name: node-215 El siguiente par\u00e1metro asegura que la memoria asignada previamente en el archivo jvm.opt se bloque\u00e9 para otras aplicaciones y sea para uso exclusivo de Elasticsearch. Su performance disminuye si esto no se cambia y realiza swapping de memoria. # ----------------------------------- Memory ----------------------------------- # Lock the memory on startup: bootstrap.memory_lock: true Como la intenci\u00f3n es crear un cluster con varios nodos, se coloca la direcci\u00f3n IP para que otros servidores se puedan comunicar con el nodo. # ---------------------------------- Network ----------------------------------- # By default Elasticsearch is only accessible on localhost. Set a different # address here to expose this node on the network: network.host: 10.91.116.215 Como ya se prob\u00f3 anteriormente, por defecto Elasticsearch se comunica por medio del puerto 9200, si se requiere cambiar esto se modifica la siguiente l\u00ednea: # By default Elasticsearch listens for HTTP traffic on the first free port it # finds starting at 9200. Set a specific HTTP port here: http.port: 9200 Aqu\u00ed se establece que el nodo puede ser elegido maestro. Un nodo maestro tiene la faculta de administrar el cl\u00faster. node.master: true Se agrega la direcci\u00f3n IP de los dem\u00e1s servidores con los que deber\u00e1 tener comunicaci\u00f3n el nodo, como en este caso se est\u00e1 configurando el nodo-215 se excluye de la lista y queda de la siguiente forma: # --------------------------------- Discovery ---------------------------------- # Pass an initial list of hosts to perform discovery when this node is started: # The default list of hosts is [\"127.0.0.1\", \"[::1]\"] discovery.seed_hosts: [\"10.91.116.145\", \"10.91.116.56\", \"10.91.116.172\"] Entonces siguiendo la l\u00f3gica anterior, la configuraci\u00f3n del nodo-56 es as\u00ed: # --------------------------------- Discovery ---------------------------------- # Pass an initial list of hosts to perform discovery when this node is started: # The default list of hosts is [\"127.0.0.1\", \"[::1]\"] discovery.seed_hosts: [\"10.91.116.145\", \"10.91.116.215\", \"10.91.116.172\"] Y as\u00ed sucesivamente con los dem\u00e1s nodos. En el siguiente par\u00e1metro se incluye el nombre de los nodos maestros iniciales, si al arranque de Elasticsearch falla la comunicaci\u00f3n con alguno de ellos, el nodo incomunicado no podr\u00e1 unirse al cluster y el servicio se detendr\u00e1 para evitar que cre\u00e9 uno propio: # Bootstrap the cluster using an initial set of master-eligible nodes: cluster.initial_master_nodes: [\"node-145\", \"node-56\"] Los servidores usados no tienen acceso a internet, as\u00ed que se debe agregar la siguiente l\u00ednea para evitar el error al querer descargar la caracter\u00edstica de geolocalizaci\u00f3n de IP en el arranque del servicio: ingest.geoip.downloader.enabled: false","title":"Configuraci\u00f3n inicial"},{"location":"Elasticsearch/3%20Implementaci%C3%B3n%20de%20seguridad.html","text":"Implementaci\u00f3n de seguridad Cuando se Elasticsearch se utiliza para pruebas de desarrollo puede funcionar sin tener ning\u00fan tipo de seguridad, sin embargo cuando se tiene un despliegue en producci\u00f3n ser\u00e1 necesario agregar capas de seguridad. Seguridad m\u00ednima Cuando se usa una licencia b\u00e1sica, las caracter\u00edsticas de seguridad est\u00e1n deshabilitadas por defecto. Para habilitarlo realizar lo siguiente en cada nodo: Detener el servicio de Elasticsearch (si est\u00e1 corriendo), y se agregar el parametro xpack.security.enabled: true en el archivo elasticsearch.yml Iniciar el servicio de Elasticsearch Crear una Keystore para elastic ./bin/elasticsearch-keystore create -p Se genera una contrase\u00f1a para los built-in users de elastic, en otra terminal correr el comando ./bin/elasticsearch-setup-passwords interactive Introducir la contrase\u00f1a para cada usuario que se pida Ahora cada comunicaci\u00f3n con Elasticsearch requerir\u00e1 de credenciales: En este punto s\u00f3lo se ha configurado la seguridad minima, como el cluster cuenta con m\u00e1s de un nodo se debe configurar el Transport Layer Security (TLS) , de lo contrario el servicio no podr\u00e1 iniciarse. Transport Layer Security (TLS) El TLS maneja toda la comunicaci\u00f3n interna entre los nodos del cluster, configurarlo previene que nodos no autorizados y/o maliciosos tengan comunicaci\u00f3n con nuestro cluster. Crear Certificate Authority (CA) En Elasticsearch los nodos usan certificados para identificarse as\u00ed mismos cuando se comunican con otros nodos. El cluster debe validar la autenticidad de estos certificados, la forma recomendada es utilizando un Certificate Authority (CA) , cuando un nodo es a\u00f1adido al cluster debe usar un certificado firmado por el mismo CA. Generar un Certificate Authority (CA) ./bin/elasticsearch-certutil ca El nombre por default es elastic-stack-ca.p12 , se puede sobreescribir si se requiere, de lo contrario introducir Enter Introducir el password a utilizar Copiar en cada nodo el certificado en la direcci\u00f3n C:\\Program Files\\elasticsearch-7.16.1\\config\\ Ahora se genera un certificado y llave privada para los nodos del cluster ./bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12 Introducir la contrase\u00f1a que se utiliz\u00f3 en el CA de los pasos anteriores Renombrar si se desea, de lo contrario introducir Enter Introducir password a usar para el certificado: Se indicar\u00e1 la direcci\u00f3n donde fueron creados los archivos Ubicar los certificados en la carpeta de configuraci\u00f3n: Copiar los archivos y copiarlos en la misma direcci\u00f3n en cada nodo. Encriptar la comunicaci\u00f3n intra-nodo con TLS Una vez generado los certificados, se habilita la configuraci\u00f3n TLS. Realizar los siguientes pasos para cada nodo. En el archivo elasticsearch.yml agregar las siguientes l\u00edneas: xpack.security.transport.ssl.enabled: true xpack.security.transport.ssl.verification_mode: certificate xpack.security.transport.ssl.client_authentication: required xpack.security.transport.ssl.keystore.path: elastic-certificates.p12 xpack.security.transport.ssl.truststore.path: elastic-certificates.p12 Agregar el password a la keystore: ./bin/elasticsearch-keystore add xpack.security.transport.ssl.keystore.secure_password ./bin/elasticsearch-keystore add xpack.security.transport.ssl.truststore.secure_password Reiniciar el servicio de Elasticsearch.","title":"Implementaci\u00f3n de seguridad"},{"location":"Elasticsearch/3%20Implementaci%C3%B3n%20de%20seguridad.html#implementacion-de-seguridad","text":"Cuando se Elasticsearch se utiliza para pruebas de desarrollo puede funcionar sin tener ning\u00fan tipo de seguridad, sin embargo cuando se tiene un despliegue en producci\u00f3n ser\u00e1 necesario agregar capas de seguridad.","title":"Implementaci\u00f3n de seguridad"},{"location":"Elasticsearch/3%20Implementaci%C3%B3n%20de%20seguridad.html#seguridad-minima","text":"Cuando se usa una licencia b\u00e1sica, las caracter\u00edsticas de seguridad est\u00e1n deshabilitadas por defecto. Para habilitarlo realizar lo siguiente en cada nodo: Detener el servicio de Elasticsearch (si est\u00e1 corriendo), y se agregar el parametro xpack.security.enabled: true en el archivo elasticsearch.yml Iniciar el servicio de Elasticsearch Crear una Keystore para elastic ./bin/elasticsearch-keystore create -p Se genera una contrase\u00f1a para los built-in users de elastic, en otra terminal correr el comando ./bin/elasticsearch-setup-passwords interactive Introducir la contrase\u00f1a para cada usuario que se pida Ahora cada comunicaci\u00f3n con Elasticsearch requerir\u00e1 de credenciales: En este punto s\u00f3lo se ha configurado la seguridad minima, como el cluster cuenta con m\u00e1s de un nodo se debe configurar el Transport Layer Security (TLS) , de lo contrario el servicio no podr\u00e1 iniciarse.","title":"Seguridad m\u00ednima"},{"location":"Elasticsearch/3%20Implementaci%C3%B3n%20de%20seguridad.html#transport-layer-security-tls","text":"El TLS maneja toda la comunicaci\u00f3n interna entre los nodos del cluster, configurarlo previene que nodos no autorizados y/o maliciosos tengan comunicaci\u00f3n con nuestro cluster.","title":"Transport Layer Security (TLS)"},{"location":"Elasticsearch/3%20Implementaci%C3%B3n%20de%20seguridad.html#crear-certificate-authority-ca","text":"En Elasticsearch los nodos usan certificados para identificarse as\u00ed mismos cuando se comunican con otros nodos. El cluster debe validar la autenticidad de estos certificados, la forma recomendada es utilizando un Certificate Authority (CA) , cuando un nodo es a\u00f1adido al cluster debe usar un certificado firmado por el mismo CA. Generar un Certificate Authority (CA) ./bin/elasticsearch-certutil ca El nombre por default es elastic-stack-ca.p12 , se puede sobreescribir si se requiere, de lo contrario introducir Enter Introducir el password a utilizar Copiar en cada nodo el certificado en la direcci\u00f3n C:\\Program Files\\elasticsearch-7.16.1\\config\\ Ahora se genera un certificado y llave privada para los nodos del cluster ./bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12 Introducir la contrase\u00f1a que se utiliz\u00f3 en el CA de los pasos anteriores Renombrar si se desea, de lo contrario introducir Enter Introducir password a usar para el certificado: Se indicar\u00e1 la direcci\u00f3n donde fueron creados los archivos Ubicar los certificados en la carpeta de configuraci\u00f3n: Copiar los archivos y copiarlos en la misma direcci\u00f3n en cada nodo.","title":"Crear Certificate Authority (CA)"},{"location":"Elasticsearch/3%20Implementaci%C3%B3n%20de%20seguridad.html#encriptar-la-comunicacion-intra-nodo-con-tls","text":"Una vez generado los certificados, se habilita la configuraci\u00f3n TLS. Realizar los siguientes pasos para cada nodo. En el archivo elasticsearch.yml agregar las siguientes l\u00edneas: xpack.security.transport.ssl.enabled: true xpack.security.transport.ssl.verification_mode: certificate xpack.security.transport.ssl.client_authentication: required xpack.security.transport.ssl.keystore.path: elastic-certificates.p12 xpack.security.transport.ssl.truststore.path: elastic-certificates.p12 Agregar el password a la keystore: ./bin/elasticsearch-keystore add xpack.security.transport.ssl.keystore.secure_password ./bin/elasticsearch-keystore add xpack.security.transport.ssl.truststore.secure_password Reiniciar el servicio de Elasticsearch.","title":"Encriptar la comunicaci\u00f3n intra-nodo con TLS"},{"location":"Kibana/4%20Kibana.html","text":"Instalaci\u00f3n Kibana es una interfaz de usuario que permite visualizar los datos de Elasticsearch y navegar en el Elastic Stack. The Non-Sucking Service Manager (NSSM) A diferencia de Elasticsearch, Kibana no cuenta con un forma nativa de instalarse como un servicio de Windows. Para lograrlo se utiliza una aplicacion de terceros llamada the Non-Sucking Service Manager (NSSM) . Descargar NSSM desde sitio oficial Descomprimir el fichero en la ubicaci\u00f3n deseada, para esta documentaci\u00f3n se hizo en C:\\Program Files Kibana Kibana puede ser instalado en un servidor que tambi\u00e9n cuente con alg\u00fana instancia de Elasticsearch, o bien hacerlo en un servidor diferente e indicar la direcci\u00f3n IP de alg\u00fan nodo. Descargar el paquete de instalaci\u00f3n desde el sitio oficial Descomprimir el fichero en la ubicaci\u00f3n deseada, para esta documentaci\u00f3n se hizo en C:\\Program Files Abrir cmd en modo administrador y dirigirse a la ruta de instalaci\u00f3n de NSSM y ejectuar nssm install kibana Se desplegar\u00e1 la siguiente ventana, donde en Path y en Startup directory se introduce lo ruta del ejecutable de Kibana, en este caso C:\\Program Files\\kibana-7.16.1-windows-x86_64\\bin\\kibana.bat y dar click en el bot\u00f3n install service Antes de arrancar el servicio se realizar\u00e1n cambios de la configuraci\u00f3n por default.","title":"Instalaci\u00f3n"},{"location":"Kibana/4%20Kibana.html#instalacion","text":"Kibana es una interfaz de usuario que permite visualizar los datos de Elasticsearch y navegar en el Elastic Stack.","title":"Instalaci\u00f3n"},{"location":"Kibana/4%20Kibana.html#the-non-sucking-service-manager-nssm","text":"A diferencia de Elasticsearch, Kibana no cuenta con un forma nativa de instalarse como un servicio de Windows. Para lograrlo se utiliza una aplicacion de terceros llamada the Non-Sucking Service Manager (NSSM) . Descargar NSSM desde sitio oficial Descomprimir el fichero en la ubicaci\u00f3n deseada, para esta documentaci\u00f3n se hizo en C:\\Program Files","title":"The Non-Sucking Service Manager (NSSM)"},{"location":"Kibana/4%20Kibana.html#kibana","text":"Kibana puede ser instalado en un servidor que tambi\u00e9n cuente con alg\u00fana instancia de Elasticsearch, o bien hacerlo en un servidor diferente e indicar la direcci\u00f3n IP de alg\u00fan nodo. Descargar el paquete de instalaci\u00f3n desde el sitio oficial Descomprimir el fichero en la ubicaci\u00f3n deseada, para esta documentaci\u00f3n se hizo en C:\\Program Files Abrir cmd en modo administrador y dirigirse a la ruta de instalaci\u00f3n de NSSM y ejectuar nssm install kibana Se desplegar\u00e1 la siguiente ventana, donde en Path y en Startup directory se introduce lo ruta del ejecutable de Kibana, en este caso C:\\Program Files\\kibana-7.16.1-windows-x86_64\\bin\\kibana.bat y dar click en el bot\u00f3n install service Antes de arrancar el servicio se realizar\u00e1n cambios de la configuraci\u00f3n por default.","title":"Kibana"},{"location":"Kibana/5%20Configuracion.html","text":"Configuraci\u00f3n El archivo de configuraci\u00f3n es kibana.yml y se encuentra en C:\\Program Files\\kibana-7.16.1-windows-x86_64\\config\\ Por default el puerto que utiliza Kibana es el 5601, si se quiere cambiar se modifica la siguiente linea: \\ # Kibana is served by a back end server. This setting specifies the port to use. server.port: 5601 Si el uso ser\u00e1 local, no es necesario cambiar el valor localhost que tiene por defecto. A contninuaci\u00f3n se coloca la direcci\u00f3n de Elasticsearch a la cu\u00e1l se conectar\u00e1, como nuestro cluster consta de 4 nodos que est\u00e1n comunicados entre ellos, se puede elegir cualquiera de ellos. elasticsearch.hosts: [\"https://10.91.116.215:9200\"] Elasticsearch cuenta con usuarios por defecto llamados built-in users , a Kibana le corresponde el siguiente: elasticsearch.username: \"kibana_system\" Cabe recordar que se gener\u00f3 una contrase\u00f1a para todos los built-in users en secciones pasadas. Se indica el tiempo de vida de la sesi\u00f3n: xpack.security.session.idleTimeout: \"1h\" xpack.security.session.lifespan: \"30d\"","title":"Configuraci\u00f3n"},{"location":"Kibana/5%20Configuracion.html#configuracion","text":"El archivo de configuraci\u00f3n es kibana.yml y se encuentra en C:\\Program Files\\kibana-7.16.1-windows-x86_64\\config\\ Por default el puerto que utiliza Kibana es el 5601, si se quiere cambiar se modifica la siguiente linea: \\ # Kibana is served by a back end server. This setting specifies the port to use. server.port: 5601 Si el uso ser\u00e1 local, no es necesario cambiar el valor localhost que tiene por defecto. A contninuaci\u00f3n se coloca la direcci\u00f3n de Elasticsearch a la cu\u00e1l se conectar\u00e1, como nuestro cluster consta de 4 nodos que est\u00e1n comunicados entre ellos, se puede elegir cualquiera de ellos. elasticsearch.hosts: [\"https://10.91.116.215:9200\"] Elasticsearch cuenta con usuarios por defecto llamados built-in users , a Kibana le corresponde el siguiente: elasticsearch.username: \"kibana_system\" Cabe recordar que se gener\u00f3 una contrase\u00f1a para todos los built-in users en secciones pasadas. Se indica el tiempo de vida de la sesi\u00f3n: xpack.security.session.idleTimeout: \"1h\" xpack.security.session.lifespan: \"30d\"","title":"Configuraci\u00f3n"},{"location":"Kibana/6%20Seguridad.html","text":"Llave de encriptaci\u00f3n y conexi\u00f3n segura a Elasticsearch Kibana guarda informaci\u00f3n interna sensible como configuraciones avanzadas o credenciales usadas para la caracter\u00edstica de Alertas. Es por ello que encripta dichos datos para no comprometer la seguridad. No es necesario ejecutar ning\u00fan batch y s\u00f3lo se a\u00f1ade cualquier cadena de 32 caracteres previo al inicio del servicio xpack.encryptedSavedObjects.encryptionKey: \"tqkIURTgToNhTEROhVAjqWOPjurHDoPQ\" xpack.security.encryptionKey: \"tqkIURTgToNhTEROhVAjqWOPjurHDoPQ\" Como anteriormente se implement\u00f3 seguridad https para toda comunicaci\u00f3n con Elasticsearch, es necesario incluir un certificado de seguridad que se cre\u00f3 previamnete. Se coloca en la carpeta config : Ahora s\u00f3lo falta habilitar esta caracteristica: elasticsearch.ssl.certificateAuthorities: C:\\Program Files\\kibana-7.15.1\\config\\elasticsearch-ca.pem","title":"Llave de encriptaci\u00f3n y conexi\u00f3n segura a Elasticsearch"},{"location":"Kibana/6%20Seguridad.html#llave-de-encriptacion-y-conexion-segura-a-elasticsearch","text":"Kibana guarda informaci\u00f3n interna sensible como configuraciones avanzadas o credenciales usadas para la caracter\u00edstica de Alertas. Es por ello que encripta dichos datos para no comprometer la seguridad. No es necesario ejecutar ning\u00fan batch y s\u00f3lo se a\u00f1ade cualquier cadena de 32 caracteres previo al inicio del servicio xpack.encryptedSavedObjects.encryptionKey: \"tqkIURTgToNhTEROhVAjqWOPjurHDoPQ\" xpack.security.encryptionKey: \"tqkIURTgToNhTEROhVAjqWOPjurHDoPQ\" Como anteriormente se implement\u00f3 seguridad https para toda comunicaci\u00f3n con Elasticsearch, es necesario incluir un certificado de seguridad que se cre\u00f3 previamnete. Se coloca en la carpeta config : Ahora s\u00f3lo falta habilitar esta caracteristica: elasticsearch.ssl.certificateAuthorities: C:\\Program Files\\kibana-7.15.1\\config\\elasticsearch-ca.pem","title":"Llave de encriptaci\u00f3n y conexi\u00f3n segura a Elasticsearch"},{"location":"Logstash/5%20Instalacion.html","text":"Instalaci\u00f3n Logstash es un agente que se encarga de recibir, filtrar y transformar datos que posteriormente ser\u00e1n enviados a Elasticsearch. Al igual que Kibana, ser\u00e1 necesario usar el aplicativo NSSM para instalar Logstash como un servicio de Windows. Descargar el paquete de instalaci\u00f3n del sitio oficial . Descomprimir el fichero en la ubicai\u00f3n deseada, para este documento se instal\u00f3 en C:\\Program Files . Abrir cmd con permisos de administrador y colocarse en la carpeta de instalci\u00f3n de NSSM para ejecutar el batch nssm install Logastah : Se desplega una ventana donde el Path y Startup directory corresponden a la direccion del archivo bat de logstash. Posteriormente dar click en Install service El servicio ya estr\u00e1 instalado pero detenido, lo siguiente es realizar la configuraci\u00f3n.","title":"Instalaci\u00f3n"},{"location":"Logstash/5%20Instalacion.html#instalacion","text":"Logstash es un agente que se encarga de recibir, filtrar y transformar datos que posteriormente ser\u00e1n enviados a Elasticsearch. Al igual que Kibana, ser\u00e1 necesario usar el aplicativo NSSM para instalar Logstash como un servicio de Windows. Descargar el paquete de instalaci\u00f3n del sitio oficial . Descomprimir el fichero en la ubicai\u00f3n deseada, para este documento se instal\u00f3 en C:\\Program Files . Abrir cmd con permisos de administrador y colocarse en la carpeta de instalci\u00f3n de NSSM para ejecutar el batch nssm install Logastah : Se desplega una ventana donde el Path y Startup directory corresponden a la direccion del archivo bat de logstash. Posteriormente dar click en Install service El servicio ya estr\u00e1 instalado pero detenido, lo siguiente es realizar la configuraci\u00f3n.","title":"Instalaci\u00f3n"},{"location":"Logstash/6%20Configuraci%C3%B3n.html","text":"Configuraci\u00f3n El archivo de configuracion se llama logstash.yml y est\u00e1 ubicada en la ruta C:\\Program Files\\logstash-7.16.1\\config . Contiene 3 secciones principales: input , filter y output . Input La informaci\u00f3n de entrada que recibe Logstash es por Filebeat o Winlogbeat (se instalar\u00e1n m\u00e1s adelante). Los dos son simplificados como beats y se comunica por medio del puerto 5044. input { beats { port => 5044 } } Filter Filter es la parte m\u00e1s importante en cuanto al tratamiento de los datos se refiere, puede contener varios pluggins y sus usos depender\u00e1n del formato en que Logstash reciba la informaci\u00f3n y el formato de salida que se requiera para indexar a Elasticsearch. Para el caso del presente proyecto existen 2 fuentes de logs, los que se escriben directamente en alg\u00fan fichero (ver ejemplo DDS) y aquellos que son generados como logs de Windows (ver ejemplo MACOPS). Para el primer caso Filebeat ser\u00e1 el encargado de enviarselo a Logstash y para el segundo ser\u00e1 Winlogbeat. Logs del sistema DDS: Logs del sistema MACOPS: Filebeat y Winlogbeat difieren en el formato de salida, por lo tanto la configuraci\u00f3n tambi\u00e9n tendr\u00e1 algunas diferencias. De ser as\u00ed se incluir\u00e1 Grok Grok es una herramienta que permite identificar partes de una cadena de texto mediante expresiones regulares y asignarlos a nuevos campos que ser\u00e1n enviados a Elasticsearch. Cuenta con un diccionario que agrupa las expresiones regulares m\u00e1s comunes y simplifica su uso. Este plugging s\u00f3lo ser\u00e1 usado para las instancias de Logstash que reciban informaci\u00f3n de Filebeat, ya que no cuentan con formato alguno, s\u00f3lo es una cadena de texto llamada message . grok { match => {\"message\" => [ \"(?m)[%{WORD:level} ] [%{TIMESTAMP_ISO8601:date}]%{GREEDYDATA:description}\", \"(?m)[%{WORD:level}] [%{TIMESTAMP_ISO8601:date}]%{GREEDYDATA:description}\", \"(?m){%{WORD:level} }{%{TIMESTAMP_ISO8601:date}}%{GREEDYDATA:description}\", \"(?m){%{WORD:level}}{%{TIMESTAMP_ISO8601:date}}%{GREEDYDATA:description}\", \"(?m)%{WORD:level} [%{TIMESTAMP_ISO8601:date}]%{GREEDYDATA:description}\" ]} } donde: (?) Indica que la cadena de texto se puede ser de multil\u00ednea. \\[%{WORD:level} \\] La barra invertida se usa como caracter de escape para ignorar los Brackets. El signo porcentaje indica el inicio de una expresi\u00f3n regular. WORD es parte del diccionario mencionado anteriormente, su equivalente regex es \\b\\w+\\b . Con esto se captura la palabra INFO, ERROR o WARN y se asigna al campo level. \\[%{TIMESTAMP_ISO8601:date}\\] Tambi\u00e9n forma de parte del diccionario y se conforma de otros t\u00e9rminos. Dependiendo el formato de la fecha depender\u00e1 del log, en esta ocasi\u00f3n se us\u00f3 el ISO8601. %{GREEDYDATA:description}\" Para el caso de uso y de los logs que se tienen, no se necesita separar m\u00e1s campos espec\u00edficos, por lo que el resto de la cadena de texto se asignara como un campo llamado descripci\u00f3n. La expresi\u00f3n Regex de GREEDYDATA es .* . Pareciera que la expresiones se repiten pero no son iguales porque difieren en el campo \\[%{WORD:level} \\] y \\[%{WORD:level}\\] , esto para prevenir errores de parseo para los casos en que el level de los logs sea [INFO] o [INFO ], por ejemplo. Mutate A diferencia de Grok, este pluggin no crea nuevos campos a partir de otros, si no que transforma los ya existentes. Los 2 son usados para las instancias de Logstash que reciben informacion de Filebeat y Winlogbeat. Cuando se recibe por Filebeat mutate { rename => {\"@timestamp\" => \"processTime\"} rename => {\"[fields][system]\" => \"system\"} rename => {\"[fields][service name]\" => \"service name\"} rename => {\"[beat][hostname]\" => \"hostname\"} lowercase => [\"[system]\"] lowercase => [\"[service name]\"] lowercase => [\"[hostname]\"] } donde: rename como su nombre indica renombra el campo de la izquierda por el de la derecha. \"@timestamp\" es la hora en que se produjo el log, Los campos con prefijo [fields] son personalizados y se agregan en la configuraci\u00f3n de Filebeat. Los que tienen prefijo [beats] son metadata de Filebeat y Winlogbeat. lowercase transforma el nombre del campo a min\u00fascula. Particularmente se eligieron estos 3 campos porque forman parte del nombre del inidice en Elasticsearch y no se admiten caracteres en mayusculas. Cuando se recibe por Winlogbeat mutate { rename => {\"message\" => \"description\"} rename => {\"[fields][system]\" => \"system\"} rename => {\"[fields][service name]\" => \"service name\"} rename => {\"[beat][hostname]\" => \"hostname\"} lowercase => [\"[system]\"] lowercase => [\"[service name]\"] lowercase => [\"[hostname]\"] uppercase => [\"level\"] } Son pr\u00e1cticamente iguales, salvo por 2 cuestiones: En Winlogbeat message contiene el cuerpo del log, lo que en Filebeat se design\u00f3 como description . level viene p\u00f3r defecto en minusculas y como los logs que se trataron con Filebeat son en mayusculas, se cambian para tenerlos en el mismo formato. Lo anterior se a\u00f1ade para tener uniformidad de los datos en Elasticsearch. Translate Este pluggin sirve para cambiar el valor de los datos en base a un diccionario, con estructura similar a un switch case . S\u00f3lo se agreg\u00f3 en instancias de Logstash que tienen como fuente a Winlogbeat porque nativamente los logs de caracter informativo en su campo level tienen el valor INFORMATION , a diferencia de los logs tratados por Filebeat cuyo valor es INFO . Entonces nuevamente se busca la uniformidad de los datos. translate { field => \"level\" target => \"level\" dictionary => { \"INFORMATION\" => \"INFO\" } } Con lo anterior se indica que se analizar\u00e1 el campo field y lo resultante ser\u00e1 modificado sobre s\u00ed mismo (opcionalmente se puede apuntar a otro campo). Si el dato tiene el valor INFORMATION entonces se sobreescribe como INFO . Date Cuando se usa Grok, por defecto la zona horaria que utiliza es UTC. Con la siguiente instrucci\u00f3n se cambia al huso horario de M\u00e9xico. date { match => [\"date\",\"YYYY-MM-dd: HH:mm:ss,SSS\", \"ISO8601\"] timezone => \"America/Mexico_City\" } Output Antes de enviar los datos a Elasticsearch es conveniente capturar errores de parseo. output { if \"_grokparsefailure\" in [tags] { file { codec => line { format => \"%{[processTime]} | %{[system]} | %{[service name]} : %{[tags]} %{[message]}\"} path => \"C:\\Program Files\\Logstash\\logs\\grokparsefailure log.txt\" } Los ficheros de logs que se utilizaron no tienen un formato \u00fanico, algunos var\u00edan por un espacio o caracter que generar\u00e1 un error en caso de que no exista alg\u00fan patron Grok que lo cumpla. Si esto ocurre Logstash a\u00f1ade el tag _grokparsefailure al objeto. Para evitar que \u00e9ste se envie a Elasticsearch con el formato incorrecto, se guarda en el archivo grokparsefailure log.txt para posterior consulta y correccion de patrones. else if \"_dateparsefailure\" in [tags]{ file { codec => line { format => \"%{[processTime]} | %{[system]} | %{[service name]} : %{[tags]} %{[message]}\"} path => \"C:\\Program Files\\Logstash\\logs\\dateparsefailure log.txt\" }","title":"Configuraci\u00f3n"},{"location":"Logstash/6%20Configuraci%C3%B3n.html#configuracion","text":"El archivo de configuracion se llama logstash.yml y est\u00e1 ubicada en la ruta C:\\Program Files\\logstash-7.16.1\\config . Contiene 3 secciones principales: input , filter y output .","title":"Configuraci\u00f3n"},{"location":"Logstash/6%20Configuraci%C3%B3n.html#input","text":"La informaci\u00f3n de entrada que recibe Logstash es por Filebeat o Winlogbeat (se instalar\u00e1n m\u00e1s adelante). Los dos son simplificados como beats y se comunica por medio del puerto 5044. input { beats { port => 5044 } }","title":"Input"},{"location":"Logstash/6%20Configuraci%C3%B3n.html#filter","text":"Filter es la parte m\u00e1s importante en cuanto al tratamiento de los datos se refiere, puede contener varios pluggins y sus usos depender\u00e1n del formato en que Logstash reciba la informaci\u00f3n y el formato de salida que se requiera para indexar a Elasticsearch. Para el caso del presente proyecto existen 2 fuentes de logs, los que se escriben directamente en alg\u00fan fichero (ver ejemplo DDS) y aquellos que son generados como logs de Windows (ver ejemplo MACOPS). Para el primer caso Filebeat ser\u00e1 el encargado de enviarselo a Logstash y para el segundo ser\u00e1 Winlogbeat. Logs del sistema DDS: Logs del sistema MACOPS: Filebeat y Winlogbeat difieren en el formato de salida, por lo tanto la configuraci\u00f3n tambi\u00e9n tendr\u00e1 algunas diferencias. De ser as\u00ed se incluir\u00e1","title":"Filter"},{"location":"Logstash/6%20Configuraci%C3%B3n.html#grok","text":"Grok es una herramienta que permite identificar partes de una cadena de texto mediante expresiones regulares y asignarlos a nuevos campos que ser\u00e1n enviados a Elasticsearch. Cuenta con un diccionario que agrupa las expresiones regulares m\u00e1s comunes y simplifica su uso. Este plugging s\u00f3lo ser\u00e1 usado para las instancias de Logstash que reciban informaci\u00f3n de Filebeat, ya que no cuentan con formato alguno, s\u00f3lo es una cadena de texto llamada message . grok { match => {\"message\" => [ \"(?m)[%{WORD:level} ] [%{TIMESTAMP_ISO8601:date}]%{GREEDYDATA:description}\", \"(?m)[%{WORD:level}] [%{TIMESTAMP_ISO8601:date}]%{GREEDYDATA:description}\", \"(?m){%{WORD:level} }{%{TIMESTAMP_ISO8601:date}}%{GREEDYDATA:description}\", \"(?m){%{WORD:level}}{%{TIMESTAMP_ISO8601:date}}%{GREEDYDATA:description}\", \"(?m)%{WORD:level} [%{TIMESTAMP_ISO8601:date}]%{GREEDYDATA:description}\" ]} } donde: (?) Indica que la cadena de texto se puede ser de multil\u00ednea. \\[%{WORD:level} \\] La barra invertida se usa como caracter de escape para ignorar los Brackets. El signo porcentaje indica el inicio de una expresi\u00f3n regular. WORD es parte del diccionario mencionado anteriormente, su equivalente regex es \\b\\w+\\b . Con esto se captura la palabra INFO, ERROR o WARN y se asigna al campo level. \\[%{TIMESTAMP_ISO8601:date}\\] Tambi\u00e9n forma de parte del diccionario y se conforma de otros t\u00e9rminos. Dependiendo el formato de la fecha depender\u00e1 del log, en esta ocasi\u00f3n se us\u00f3 el ISO8601. %{GREEDYDATA:description}\" Para el caso de uso y de los logs que se tienen, no se necesita separar m\u00e1s campos espec\u00edficos, por lo que el resto de la cadena de texto se asignara como un campo llamado descripci\u00f3n. La expresi\u00f3n Regex de GREEDYDATA es .* . Pareciera que la expresiones se repiten pero no son iguales porque difieren en el campo \\[%{WORD:level} \\] y \\[%{WORD:level}\\] , esto para prevenir errores de parseo para los casos en que el level de los logs sea [INFO] o [INFO ], por ejemplo.","title":"Grok"},{"location":"Logstash/6%20Configuraci%C3%B3n.html#mutate","text":"A diferencia de Grok, este pluggin no crea nuevos campos a partir de otros, si no que transforma los ya existentes. Los 2 son usados para las instancias de Logstash que reciben informacion de Filebeat y Winlogbeat.","title":"Mutate"},{"location":"Logstash/6%20Configuraci%C3%B3n.html#cuando-se-recibe-por-filebeat","text":"mutate { rename => {\"@timestamp\" => \"processTime\"} rename => {\"[fields][system]\" => \"system\"} rename => {\"[fields][service name]\" => \"service name\"} rename => {\"[beat][hostname]\" => \"hostname\"} lowercase => [\"[system]\"] lowercase => [\"[service name]\"] lowercase => [\"[hostname]\"] } donde: rename como su nombre indica renombra el campo de la izquierda por el de la derecha. \"@timestamp\" es la hora en que se produjo el log, Los campos con prefijo [fields] son personalizados y se agregan en la configuraci\u00f3n de Filebeat. Los que tienen prefijo [beats] son metadata de Filebeat y Winlogbeat. lowercase transforma el nombre del campo a min\u00fascula. Particularmente se eligieron estos 3 campos porque forman parte del nombre del inidice en Elasticsearch y no se admiten caracteres en mayusculas.","title":"Cuando se recibe por Filebeat"},{"location":"Logstash/6%20Configuraci%C3%B3n.html#cuando-se-recibe-por-winlogbeat","text":"mutate { rename => {\"message\" => \"description\"} rename => {\"[fields][system]\" => \"system\"} rename => {\"[fields][service name]\" => \"service name\"} rename => {\"[beat][hostname]\" => \"hostname\"} lowercase => [\"[system]\"] lowercase => [\"[service name]\"] lowercase => [\"[hostname]\"] uppercase => [\"level\"] } Son pr\u00e1cticamente iguales, salvo por 2 cuestiones: En Winlogbeat message contiene el cuerpo del log, lo que en Filebeat se design\u00f3 como description . level viene p\u00f3r defecto en minusculas y como los logs que se trataron con Filebeat son en mayusculas, se cambian para tenerlos en el mismo formato. Lo anterior se a\u00f1ade para tener uniformidad de los datos en Elasticsearch.","title":"Cuando se recibe por Winlogbeat"},{"location":"Logstash/6%20Configuraci%C3%B3n.html#translate","text":"Este pluggin sirve para cambiar el valor de los datos en base a un diccionario, con estructura similar a un switch case . S\u00f3lo se agreg\u00f3 en instancias de Logstash que tienen como fuente a Winlogbeat porque nativamente los logs de caracter informativo en su campo level tienen el valor INFORMATION , a diferencia de los logs tratados por Filebeat cuyo valor es INFO . Entonces nuevamente se busca la uniformidad de los datos. translate { field => \"level\" target => \"level\" dictionary => { \"INFORMATION\" => \"INFO\" } } Con lo anterior se indica que se analizar\u00e1 el campo field y lo resultante ser\u00e1 modificado sobre s\u00ed mismo (opcionalmente se puede apuntar a otro campo). Si el dato tiene el valor INFORMATION entonces se sobreescribe como INFO .","title":"Translate"},{"location":"Logstash/6%20Configuraci%C3%B3n.html#date","text":"Cuando se usa Grok, por defecto la zona horaria que utiliza es UTC. Con la siguiente instrucci\u00f3n se cambia al huso horario de M\u00e9xico. date { match => [\"date\",\"YYYY-MM-dd: HH:mm:ss,SSS\", \"ISO8601\"] timezone => \"America/Mexico_City\" }","title":"Date"},{"location":"Logstash/6%20Configuraci%C3%B3n.html#output","text":"Antes de enviar los datos a Elasticsearch es conveniente capturar errores de parseo. output { if \"_grokparsefailure\" in [tags] { file { codec => line { format => \"%{[processTime]} | %{[system]} | %{[service name]} : %{[tags]} %{[message]}\"} path => \"C:\\Program Files\\Logstash\\logs\\grokparsefailure log.txt\" } Los ficheros de logs que se utilizaron no tienen un formato \u00fanico, algunos var\u00edan por un espacio o caracter que generar\u00e1 un error en caso de que no exista alg\u00fan patron Grok que lo cumpla. Si esto ocurre Logstash a\u00f1ade el tag _grokparsefailure al objeto. Para evitar que \u00e9ste se envie a Elasticsearch con el formato incorrecto, se guarda en el archivo grokparsefailure log.txt para posterior consulta y correccion de patrones. else if \"_dateparsefailure\" in [tags]{ file { codec => line { format => \"%{[processTime]} | %{[system]} | %{[service name]} : %{[tags]} %{[message]}\"} path => \"C:\\Program Files\\Logstash\\logs\\dateparsefailure log.txt\" }","title":"Output"}]}